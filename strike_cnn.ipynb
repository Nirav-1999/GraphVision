{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "strike_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvJhXdmDb45x"
      },
      "source": [
        "# **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBJgfqGfb_tH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1250caf2-f644-415b-9d42-fec4491805c7"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import os\n",
        "from google.colab import files\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWttJRzKqXWy"
      },
      "source": [
        "# **Import Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqTLdt_-cVqt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb84a85c-6cef-4ba7-f467-a48535cc627b"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/mntDrive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /mntDrive; to attempt to forcibly remount, call drive.mount(\"/mntDrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAQh9r36qy4G"
      },
      "source": [
        "# **CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMPy0aRurxq9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "508e7659-84af-4542-d930-e4e8e9d988b0"
      },
      "source": [
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "#Convolution2D(no_filters,kernel_height,kernel_width,input_img_shape,activation_func)\n",
        "classifier.add(Convolution2D(32, 3, 3, input_shape = (128, 128, 3), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 4, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the CNN\n",
        "#If more than two outcomes than loss='categorical_crossentropy'\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(128, 128,..., activation=\"relu\")`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWrKdXIXr4wY"
      },
      "source": [
        "# **Fitting the CNN to images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAGp5ol4r9vt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4173050f-cae5-4198-c8a9-2960e704f814"
      },
      "source": [
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/mntDrive/My Drive/Strike dataset/training_set',\n",
        "                                                 target_size = (128, 128),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/mntDrive/My Drive/Strike dataset/test_set',\n",
        "                                            target_size = (128, 128),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "filepath=\"/mntDrive/My Drive/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "classifier.fit_generator(training_set,\n",
        "                         samples_per_epoch = 847, #Change\n",
        "                         nb_epoch = 50,\n",
        "                         validation_data = test_set,\n",
        "                         nb_val_samples = 147)    #Change\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 830 images belonging to 4 classes.\n",
            "Found 213 images belonging to 4 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=26, epochs=50, validation_steps=147)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "26/26 [==============================] - 369s 14s/step - loss: 1.4132 - acc: 0.2654 - val_loss: 1.3903 - val_acc: 0.2300\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 1.3693 - acc: 0.2998 - val_loss: 1.4354 - val_acc: 0.1315\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 1.3150 - acc: 0.1952 - val_loss: 1.9796 - val_acc: 0.1221\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 1.2760 - acc: 0.1857 - val_loss: 2.0718 - val_acc: 0.0986\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 1.2589 - acc: 0.2339 - val_loss: 3.0614 - val_acc: 0.1362\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 1.2418 - acc: 0.2422 - val_loss: 2.8772 - val_acc: 0.1362\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 1.2860 - acc: 0.2202 - val_loss: 1.8117 - val_acc: 0.1221\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 1.2988 - acc: 0.2447 - val_loss: 1.5975 - val_acc: 0.1174\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 1.2943 - acc: 0.2443 - val_loss: 2.8155 - val_acc: 0.1455\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 1.2368 - acc: 0.2579 - val_loss: 2.2442 - val_acc: 0.1408\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 1.2404 - acc: 0.2696 - val_loss: 2.7343 - val_acc: 0.1643\n",
            "Epoch 12/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 1.2399 - acc: 0.2530 - val_loss: 2.6773 - val_acc: 0.1408\n",
            "Epoch 13/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 1.2335 - acc: 0.2699 - val_loss: 3.0666 - val_acc: 0.1596\n",
            "Epoch 14/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 1.2429 - acc: 0.2627 - val_loss: 1.9189 - val_acc: 0.1784\n",
            "Epoch 15/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 1.2974 - acc: 0.2397 - val_loss: 3.0143 - val_acc: 0.2019\n",
            "Epoch 16/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 1.2485 - acc: 0.3167 - val_loss: 3.0576 - val_acc: 0.2629\n",
            "Epoch 17/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 1.2176 - acc: 0.3798 - val_loss: 2.7072 - val_acc: 0.2770\n",
            "Epoch 18/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 1.1870 - acc: 0.4364 - val_loss: 2.8306 - val_acc: 0.3756\n",
            "Epoch 19/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 1.0201 - acc: 0.5799 - val_loss: 3.6252 - val_acc: 0.3803\n",
            "Epoch 20/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 0.7905 - acc: 0.6820 - val_loss: 2.6289 - val_acc: 0.5540\n",
            "Epoch 21/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 0.6592 - acc: 0.7265 - val_loss: 3.0660 - val_acc: 0.4977\n",
            "Epoch 22/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 0.5442 - acc: 0.7893 - val_loss: 2.9365 - val_acc: 0.5446\n",
            "Epoch 23/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 0.4921 - acc: 0.8060 - val_loss: 2.9260 - val_acc: 0.5399\n",
            "Epoch 24/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 0.4876 - acc: 0.7941 - val_loss: 3.2019 - val_acc: 0.5728\n",
            "Epoch 25/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 0.4251 - acc: 0.8491 - val_loss: 3.0813 - val_acc: 0.5540\n",
            "Epoch 26/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 0.3964 - acc: 0.8460 - val_loss: 3.1539 - val_acc: 0.5822\n",
            "Epoch 27/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 0.4151 - acc: 0.8471 - val_loss: 3.0267 - val_acc: 0.5775\n",
            "Epoch 28/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 0.3227 - acc: 0.8929 - val_loss: 3.6346 - val_acc: 0.5869\n",
            "Epoch 29/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 0.3195 - acc: 0.8724 - val_loss: 3.5723 - val_acc: 0.5728\n",
            "Epoch 30/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 0.3129 - acc: 0.8785 - val_loss: 3.3370 - val_acc: 0.5822\n",
            "Epoch 31/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 0.2865 - acc: 0.8865 - val_loss: 2.9554 - val_acc: 0.5869\n",
            "Epoch 32/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 0.2296 - acc: 0.9157 - val_loss: 3.4227 - val_acc: 0.5962\n",
            "Epoch 33/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 0.2355 - acc: 0.9135 - val_loss: 3.5920 - val_acc: 0.5822\n",
            "Epoch 34/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 0.1936 - acc: 0.9386 - val_loss: 4.2394 - val_acc: 0.5681\n",
            "Epoch 35/50\n",
            "26/26 [==============================] - 104s 4s/step - loss: 0.2153 - acc: 0.9252 - val_loss: 3.6763 - val_acc: 0.5822\n",
            "Epoch 36/50\n",
            "26/26 [==============================] - 105s 4s/step - loss: 0.2115 - acc: 0.9204 - val_loss: 3.7646 - val_acc: 0.6009\n",
            "Epoch 37/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.1844 - acc: 0.9249"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVYKZ1-Kc5Yv"
      },
      "source": [
        "from google.colab import files\n",
        "print(\"HI\")\n",
        "import pickle\n",
        "with open('checkpoint','ab') as checkpoint:\n",
        "  pickle.dump(classifier,checkpoint)\n",
        "print(classifier)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}